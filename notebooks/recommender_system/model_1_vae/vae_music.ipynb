{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "artists = pd.read_csv(\"../../../data/processed/artists.csv\")\n",
    "tracks = pd.read_json(\"../../../data/v2/tracks.json\")\n",
    "track_storage = pd.read_json(\"../../../data/v2/track_storage.json\")\n",
    "users = pd.read_json(\"../../../data/v2/users.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess tracks data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                       id                                               name  \\\n0  0RNxWy0PC3AyH4ThH3aGK6                                     Mack the Knife   \n1  2W889aLIKxULEefrleFBFI                           Someone to Watch Over Me   \n2  4Pnzw1nLOpDNV6MKI5ueIR     Nancy (With the Laughing Face) - 78rpm Version   \n3  7GLmfKOe5BfOXk7334DoKt  Saturday Night (Is The Loneliest Night In The ...   \n4  6kD1SNGPkfX9LwaGd1FG92             Put Your Dreams Away (For Another Day)   \n\n   popularity  duration_ms  explicit               id_artist release_date  \\\n0          55       201467         0  19eLuQmk9aCobbVDHc6eek         1929   \n1          54       198000         0  1Mxqyy3pSjf8kZZL4QVxS0         1943   \n2          55       199000         0  1Mxqyy3pSjf8kZZL4QVxS0         1944   \n3          54       163000         0  1Mxqyy3pSjf8kZZL4QVxS0         1944   \n4          53       186173         0  1Mxqyy3pSjf8kZZL4QVxS0         1944   \n\n   danceability  energy  key  loudness  speechiness  acousticness  \\\n0         0.673  0.3770    0   -14.141       0.0697         0.586   \n1         0.204  0.1510    2   -17.842       0.0418         0.947   \n2         0.295  0.0826    1   -19.569       0.0367         0.984   \n3         0.561  0.3350    9   -11.093       0.0499         0.840   \n4         0.197  0.0546    1   -22.411       0.0346         0.950   \n\n   instrumentalness  liveness  valence    tempo  \n0          0.000000     0.332    0.713   88.973  \n1          0.000009     0.321    0.134   91.783  \n2          0.000358     0.156    0.169  128.600  \n3          0.000002     0.788    0.590  126.974  \n4          0.276000     0.152    0.100   90.150  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>explicit</th>\n      <th>id_artist</th>\n      <th>release_date</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0RNxWy0PC3AyH4ThH3aGK6</td>\n      <td>Mack the Knife</td>\n      <td>55</td>\n      <td>201467</td>\n      <td>0</td>\n      <td>19eLuQmk9aCobbVDHc6eek</td>\n      <td>1929</td>\n      <td>0.673</td>\n      <td>0.3770</td>\n      <td>0</td>\n      <td>-14.141</td>\n      <td>0.0697</td>\n      <td>0.586</td>\n      <td>0.000000</td>\n      <td>0.332</td>\n      <td>0.713</td>\n      <td>88.973</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2W889aLIKxULEefrleFBFI</td>\n      <td>Someone to Watch Over Me</td>\n      <td>54</td>\n      <td>198000</td>\n      <td>0</td>\n      <td>1Mxqyy3pSjf8kZZL4QVxS0</td>\n      <td>1943</td>\n      <td>0.204</td>\n      <td>0.1510</td>\n      <td>2</td>\n      <td>-17.842</td>\n      <td>0.0418</td>\n      <td>0.947</td>\n      <td>0.000009</td>\n      <td>0.321</td>\n      <td>0.134</td>\n      <td>91.783</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4Pnzw1nLOpDNV6MKI5ueIR</td>\n      <td>Nancy (With the Laughing Face) - 78rpm Version</td>\n      <td>55</td>\n      <td>199000</td>\n      <td>0</td>\n      <td>1Mxqyy3pSjf8kZZL4QVxS0</td>\n      <td>1944</td>\n      <td>0.295</td>\n      <td>0.0826</td>\n      <td>1</td>\n      <td>-19.569</td>\n      <td>0.0367</td>\n      <td>0.984</td>\n      <td>0.000358</td>\n      <td>0.156</td>\n      <td>0.169</td>\n      <td>128.600</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7GLmfKOe5BfOXk7334DoKt</td>\n      <td>Saturday Night (Is The Loneliest Night In The ...</td>\n      <td>54</td>\n      <td>163000</td>\n      <td>0</td>\n      <td>1Mxqyy3pSjf8kZZL4QVxS0</td>\n      <td>1944</td>\n      <td>0.561</td>\n      <td>0.3350</td>\n      <td>9</td>\n      <td>-11.093</td>\n      <td>0.0499</td>\n      <td>0.840</td>\n      <td>0.000002</td>\n      <td>0.788</td>\n      <td>0.590</td>\n      <td>126.974</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6kD1SNGPkfX9LwaGd1FG92</td>\n      <td>Put Your Dreams Away (For Another Day)</td>\n      <td>53</td>\n      <td>186173</td>\n      <td>0</td>\n      <td>1Mxqyy3pSjf8kZZL4QVxS0</td>\n      <td>1944</td>\n      <td>0.197</td>\n      <td>0.0546</td>\n      <td>1</td>\n      <td>-22.411</td>\n      <td>0.0346</td>\n      <td>0.950</td>\n      <td>0.276000</td>\n      <td>0.152</td>\n      <td>0.100</td>\n      <td>90.150</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "track_ids = tracks.id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "VALID_COLUMN_NAMES = ['duration_ms', 'popularity', 'explicit', 'release_date','danceability', 'energy', 'key', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   duration_ms  popularity  explicit release_date  danceability  energy  key  \\\n0       201467          55         0         1929         0.673  0.3770    0   \n1       198000          54         0         1943         0.204  0.1510    2   \n2       199000          55         0         1944         0.295  0.0826    1   \n3       163000          54         0         1944         0.561  0.3350    9   \n4       186173          53         0         1944         0.197  0.0546    1   \n\n   loudness  speechiness  acousticness  instrumentalness  liveness  valence  \\\n0   -14.141       0.0697         0.586          0.000000     0.332    0.713   \n1   -17.842       0.0418         0.947          0.000009     0.321    0.134   \n2   -19.569       0.0367         0.984          0.000358     0.156    0.169   \n3   -11.093       0.0499         0.840          0.000002     0.788    0.590   \n4   -22.411       0.0346         0.950          0.276000     0.152    0.100   \n\n     tempo  \n0   88.973  \n1   91.783  \n2  128.600  \n3  126.974  \n4   90.150  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_ms</th>\n      <th>popularity</th>\n      <th>explicit</th>\n      <th>release_date</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201467</td>\n      <td>55</td>\n      <td>0</td>\n      <td>1929</td>\n      <td>0.673</td>\n      <td>0.3770</td>\n      <td>0</td>\n      <td>-14.141</td>\n      <td>0.0697</td>\n      <td>0.586</td>\n      <td>0.000000</td>\n      <td>0.332</td>\n      <td>0.713</td>\n      <td>88.973</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>198000</td>\n      <td>54</td>\n      <td>0</td>\n      <td>1943</td>\n      <td>0.204</td>\n      <td>0.1510</td>\n      <td>2</td>\n      <td>-17.842</td>\n      <td>0.0418</td>\n      <td>0.947</td>\n      <td>0.000009</td>\n      <td>0.321</td>\n      <td>0.134</td>\n      <td>91.783</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>199000</td>\n      <td>55</td>\n      <td>0</td>\n      <td>1944</td>\n      <td>0.295</td>\n      <td>0.0826</td>\n      <td>1</td>\n      <td>-19.569</td>\n      <td>0.0367</td>\n      <td>0.984</td>\n      <td>0.000358</td>\n      <td>0.156</td>\n      <td>0.169</td>\n      <td>128.600</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>163000</td>\n      <td>54</td>\n      <td>0</td>\n      <td>1944</td>\n      <td>0.561</td>\n      <td>0.3350</td>\n      <td>9</td>\n      <td>-11.093</td>\n      <td>0.0499</td>\n      <td>0.840</td>\n      <td>0.000002</td>\n      <td>0.788</td>\n      <td>0.590</td>\n      <td>126.974</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>186173</td>\n      <td>53</td>\n      <td>0</td>\n      <td>1944</td>\n      <td>0.197</td>\n      <td>0.0546</td>\n      <td>1</td>\n      <td>-22.411</td>\n      <td>0.0346</td>\n      <td>0.950</td>\n      <td>0.276000</td>\n      <td>0.152</td>\n      <td>0.100</td>\n      <td>90.150</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks = tracks[VALID_COLUMN_NAMES]\n",
    "tracks.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "duration_ms           int64\npopularity            int64\nexplicit              int64\nrelease_date         object\ndanceability        float64\nenergy              float64\nkey                   int64\nloudness            float64\nspeechiness         float64\nacousticness        float64\ninstrumentalness    float64\nliveness            float64\nvalence             float64\ntempo               float64\ndtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Release date\n",
    "\n",
    "Simplify this column to just have a year of the song release"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "rd = tracks.release_date\n",
    "rd = pd.to_datetime(rd, errors='coerce')\n",
    "tracks['release_date'] = rd.dt.year.fillna(0).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standarizing columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   duration_ms  popularity  explicit  release_date  danceability  energy  key  \\\n0       201467          55         0          1929         0.673  0.3770    0   \n1       198000          54         0          1943         0.204  0.1510    2   \n2       199000          55         0          1944         0.295  0.0826    1   \n3       163000          54         0          1944         0.561  0.3350    9   \n4       186173          53         0          1944         0.197  0.0546    1   \n\n   loudness  speechiness  acousticness  instrumentalness  liveness  valence  \\\n0   -14.141       0.0697         0.586          0.000000     0.332    0.713   \n1   -17.842       0.0418         0.947          0.000009     0.321    0.134   \n2   -19.569       0.0367         0.984          0.000358     0.156    0.169   \n3   -11.093       0.0499         0.840          0.000002     0.788    0.590   \n4   -22.411       0.0346         0.950          0.276000     0.152    0.100   \n\n     tempo  \n0   88.973  \n1   91.783  \n2  128.600  \n3  126.974  \n4   90.150  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_ms</th>\n      <th>popularity</th>\n      <th>explicit</th>\n      <th>release_date</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201467</td>\n      <td>55</td>\n      <td>0</td>\n      <td>1929</td>\n      <td>0.673</td>\n      <td>0.3770</td>\n      <td>0</td>\n      <td>-14.141</td>\n      <td>0.0697</td>\n      <td>0.586</td>\n      <td>0.000000</td>\n      <td>0.332</td>\n      <td>0.713</td>\n      <td>88.973</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>198000</td>\n      <td>54</td>\n      <td>0</td>\n      <td>1943</td>\n      <td>0.204</td>\n      <td>0.1510</td>\n      <td>2</td>\n      <td>-17.842</td>\n      <td>0.0418</td>\n      <td>0.947</td>\n      <td>0.000009</td>\n      <td>0.321</td>\n      <td>0.134</td>\n      <td>91.783</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>199000</td>\n      <td>55</td>\n      <td>0</td>\n      <td>1944</td>\n      <td>0.295</td>\n      <td>0.0826</td>\n      <td>1</td>\n      <td>-19.569</td>\n      <td>0.0367</td>\n      <td>0.984</td>\n      <td>0.000358</td>\n      <td>0.156</td>\n      <td>0.169</td>\n      <td>128.600</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>163000</td>\n      <td>54</td>\n      <td>0</td>\n      <td>1944</td>\n      <td>0.561</td>\n      <td>0.3350</td>\n      <td>9</td>\n      <td>-11.093</td>\n      <td>0.0499</td>\n      <td>0.840</td>\n      <td>0.000002</td>\n      <td>0.788</td>\n      <td>0.590</td>\n      <td>126.974</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>186173</td>\n      <td>53</td>\n      <td>0</td>\n      <td>1944</td>\n      <td>0.197</td>\n      <td>0.0546</td>\n      <td>1</td>\n      <td>-22.411</td>\n      <td>0.0346</td>\n      <td>0.950</td>\n      <td>0.276000</td>\n      <td>0.152</td>\n      <td>0.100</td>\n      <td>90.150</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "tracks = pd.DataFrame(scaler.fit_transform(tracks), columns=tracks.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   duration_ms  popularity  explicit  release_date  danceability    energy  \\\n0    -0.397693   -0.792191 -0.447118     -5.542188      0.466992 -1.293191   \n1    -0.445783   -0.916444 -0.447118     -4.536483     -2.496578 -2.371576   \n2    -0.431913   -0.792191 -0.447118     -4.464647     -1.921557 -2.697954   \n3    -0.931261   -0.916444 -0.447118     -4.464647     -0.240726 -1.493599   \n4    -0.609833   -1.040697 -0.447118     -4.464647     -2.540810 -2.831560   \n\n        key  loudness  speechiness  acousticness  instrumentalness  liveness  \\\n0 -1.483343 -1.857878    -0.147948      1.152614         -0.263179  0.826836   \n1 -0.921346 -2.847975    -0.460325      2.460088         -0.263119  0.761337   \n2 -1.202345 -3.309985    -0.517426      2.594095         -0.260837 -0.221159   \n3  1.045646 -1.042471    -0.369635      2.072554         -0.263169  3.542097   \n4 -1.202345 -4.070282    -0.540938      2.470953          1.542815 -0.244977   \n\n    valence     tempo  \n0  0.797638 -1.112254  \n1 -1.570737 -1.017368  \n2 -1.427571  0.225836  \n3  0.294512  0.170931  \n4 -1.709812 -1.072510  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_ms</th>\n      <th>popularity</th>\n      <th>explicit</th>\n      <th>release_date</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.397693</td>\n      <td>-0.792191</td>\n      <td>-0.447118</td>\n      <td>-5.542188</td>\n      <td>0.466992</td>\n      <td>-1.293191</td>\n      <td>-1.483343</td>\n      <td>-1.857878</td>\n      <td>-0.147948</td>\n      <td>1.152614</td>\n      <td>-0.263179</td>\n      <td>0.826836</td>\n      <td>0.797638</td>\n      <td>-1.112254</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.445783</td>\n      <td>-0.916444</td>\n      <td>-0.447118</td>\n      <td>-4.536483</td>\n      <td>-2.496578</td>\n      <td>-2.371576</td>\n      <td>-0.921346</td>\n      <td>-2.847975</td>\n      <td>-0.460325</td>\n      <td>2.460088</td>\n      <td>-0.263119</td>\n      <td>0.761337</td>\n      <td>-1.570737</td>\n      <td>-1.017368</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.431913</td>\n      <td>-0.792191</td>\n      <td>-0.447118</td>\n      <td>-4.464647</td>\n      <td>-1.921557</td>\n      <td>-2.697954</td>\n      <td>-1.202345</td>\n      <td>-3.309985</td>\n      <td>-0.517426</td>\n      <td>2.594095</td>\n      <td>-0.260837</td>\n      <td>-0.221159</td>\n      <td>-1.427571</td>\n      <td>0.225836</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.931261</td>\n      <td>-0.916444</td>\n      <td>-0.447118</td>\n      <td>-4.464647</td>\n      <td>-0.240726</td>\n      <td>-1.493599</td>\n      <td>1.045646</td>\n      <td>-1.042471</td>\n      <td>-0.369635</td>\n      <td>2.072554</td>\n      <td>-0.263169</td>\n      <td>3.542097</td>\n      <td>0.294512</td>\n      <td>0.170931</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.609833</td>\n      <td>-1.040697</td>\n      <td>-0.447118</td>\n      <td>-4.464647</td>\n      <td>-2.540810</td>\n      <td>-2.831560</td>\n      <td>-1.202345</td>\n      <td>-4.070282</td>\n      <td>-0.540938</td>\n      <td>2.470953</td>\n      <td>1.542815</td>\n      <td>-0.244977</td>\n      <td>-1.709812</td>\n      <td>-1.072510</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Key column\n",
    "\n",
    "This column contains the categorical columns wih low cardinality. So it will be One Hot Encoded."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "-1.483343    2631\n 0.483649    2433\n 1.045646    2359\n-0.921346    2308\n-1.202345    2052\n-0.359348    1866\n-0.078349    1854\n 1.607644    1768\n 0.202650    1522\n 0.764647    1441\n 1.326645    1429\n-0.640347     749\nName: key, dtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.key.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tracks = pd.get_dummies(tracks, columns=['key'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['duration_ms', 'popularity', 'explicit', 'release_date', 'danceability',\n       'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness',\n       'liveness', 'valence', 'tempo', 'key_-1.4833434758561947',\n       'key_-1.202344617097444', 'key_-0.9213457583386933',\n       'key_-0.6403468995799425', 'key_-0.3593480408211918',\n       'key_-0.07834918206244113', 'key_0.20264967669630957',\n       'key_0.4836485354550603', 'key_0.764647394213811',\n       'key_1.0456462529725616', 'key_1.3266451117313125',\n       'key_1.6076439704900631'],\n      dtype='object')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(22412, 25)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "   duration_ms  popularity  explicit  release_date  danceability    energy  \\\n0    -0.397693   -0.792191 -0.447118     -5.542188      0.466992 -1.293191   \n1    -0.445783   -0.916444 -0.447118     -4.536483     -2.496578 -2.371576   \n2    -0.431913   -0.792191 -0.447118     -4.464647     -1.921557 -2.697954   \n3    -0.931261   -0.916444 -0.447118     -4.464647     -0.240726 -1.493599   \n4    -0.609833   -1.040697 -0.447118     -4.464647     -2.540810 -2.831560   \n\n   loudness  speechiness  acousticness  instrumentalness  ...  \\\n0 -1.857878    -0.147948      1.152614         -0.263179  ...   \n1 -2.847975    -0.460325      2.460088         -0.263119  ...   \n2 -3.309985    -0.517426      2.594095         -0.260837  ...   \n3 -1.042471    -0.369635      2.072554         -0.263169  ...   \n4 -4.070282    -0.540938      2.470953          1.542815  ...   \n\n   key_-0.9213457583386933  key_-0.6403468995799425  key_-0.3593480408211918  \\\n0                        0                        0                        0   \n1                        1                        0                        0   \n2                        0                        0                        0   \n3                        0                        0                        0   \n4                        0                        0                        0   \n\n   key_-0.07834918206244113  key_0.20264967669630957  key_0.4836485354550603  \\\n0                         0                        0                       0   \n1                         0                        0                       0   \n2                         0                        0                       0   \n3                         0                        0                       0   \n4                         0                        0                       0   \n\n   key_0.764647394213811  key_1.0456462529725616  key_1.3266451117313125  \\\n0                      0                       0                       0   \n1                      0                       0                       0   \n2                      0                       0                       0   \n3                      0                       1                       0   \n4                      0                       0                       0   \n\n   key_1.6076439704900631  \n0                       0  \n1                       0  \n2                       0  \n3                       0  \n4                       0  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_ms</th>\n      <th>popularity</th>\n      <th>explicit</th>\n      <th>release_date</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>...</th>\n      <th>key_-0.9213457583386933</th>\n      <th>key_-0.6403468995799425</th>\n      <th>key_-0.3593480408211918</th>\n      <th>key_-0.07834918206244113</th>\n      <th>key_0.20264967669630957</th>\n      <th>key_0.4836485354550603</th>\n      <th>key_0.764647394213811</th>\n      <th>key_1.0456462529725616</th>\n      <th>key_1.3266451117313125</th>\n      <th>key_1.6076439704900631</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.397693</td>\n      <td>-0.792191</td>\n      <td>-0.447118</td>\n      <td>-5.542188</td>\n      <td>0.466992</td>\n      <td>-1.293191</td>\n      <td>-1.857878</td>\n      <td>-0.147948</td>\n      <td>1.152614</td>\n      <td>-0.263179</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.445783</td>\n      <td>-0.916444</td>\n      <td>-0.447118</td>\n      <td>-4.536483</td>\n      <td>-2.496578</td>\n      <td>-2.371576</td>\n      <td>-2.847975</td>\n      <td>-0.460325</td>\n      <td>2.460088</td>\n      <td>-0.263119</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.431913</td>\n      <td>-0.792191</td>\n      <td>-0.447118</td>\n      <td>-4.464647</td>\n      <td>-1.921557</td>\n      <td>-2.697954</td>\n      <td>-3.309985</td>\n      <td>-0.517426</td>\n      <td>2.594095</td>\n      <td>-0.260837</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.931261</td>\n      <td>-0.916444</td>\n      <td>-0.447118</td>\n      <td>-4.464647</td>\n      <td>-0.240726</td>\n      <td>-1.493599</td>\n      <td>-1.042471</td>\n      <td>-0.369635</td>\n      <td>2.072554</td>\n      <td>-0.263169</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.609833</td>\n      <td>-1.040697</td>\n      <td>-0.447118</td>\n      <td>-4.464647</td>\n      <td>-2.540810</td>\n      <td>-2.831560</td>\n      <td>-4.070282</td>\n      <td>-0.540938</td>\n      <td>2.470953</td>\n      <td>1.542815</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train VAE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, decomposition, manifold, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "import time\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.compat.v1.keras.layers import Input, Dense, LeakyReLU, Conv2D, MaxPooling2D, UpSampling2D,  Concatenate\n",
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.compat.v1.keras.layers import Dense, Reshape, Flatten\n",
    "from tensorflow.compat.v1.keras.layers import Dropout,BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, logcosh\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_features (InputLayer)    [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           832         ['input_features[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           2112        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          8320        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 64)           8256        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 64)           8256        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 64)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,776\n",
      "Trainable params: 27,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z (InputLayer)              [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 25)                825       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,481\n",
      "Trainable params: 19,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"vae\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_features (InputLayer)    [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           832         ['input_features[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           2112        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          8320        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 64)           8256        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 64)           8256        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 64)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 25)           19481       ['sampling[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47,257\n",
      "Trainable params: 47,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the encoder model\n",
    "input_features = keras.Input(shape=(25,), name=\"input_features\")\n",
    "x = Dense(32, activation=\"relu\")(input_features)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "z_mean = Dense(64, name=\"z_mean\")(x)\n",
    "z_log_var = Dense(64, name=\"z_log_var\")(x)\n",
    "\n",
    "# Define the sampling layer to sample from the latent space\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        latent_dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "# Define the decoder model\n",
    "latent_inputs = Input(shape=(64,), name=\"z\")\n",
    "x = Dense(128, activation=\"relu\")(latent_inputs)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "outputs = Dense(25, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Define the VAE model\n",
    "encoder = Model(inputs=input_features, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "decoder = Model(inputs=latent_inputs, outputs=outputs, name=\"decoder\")\n",
    "outputs = decoder(z)\n",
    "vae = Model(inputs=input_features, outputs=outputs, name=\"vae\")\n",
    "\n",
    "# Print the summary of the models\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "vae.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "VAE 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def kl_loss(z_mean, z_log_var):\n",
    "    \"\"\"Calculates the KL divergence loss.\"\"\"\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "    return kl_loss\n",
    "\n",
    "def reconstruction_loss(inputs, reconstructed):\n",
    "    mse = tf.keras.losses.MeanAbsoluteError()\n",
    "    loss = mse(inputs, reconstructed)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, vae_optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z_mean, z_log_var, z = encoder(inputs)\n",
    "        reconstructed = decoder(z)\n",
    "        reconstruction_losses = reconstruction_loss(inputs, reconstructed)\n",
    "        kl_losses = kl_loss(z_mean, z_log_var)\n",
    "        loss = tf.reduce_mean(reconstruction_losses + kl_losses)\n",
    "    gradients = tape.gradient(loss, vae.trainable_variables)\n",
    "    vae_optimizer.apply_gradients(zip(gradients, vae.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train(train_dataset, epochs, vae_optimizer):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in train_dataset:\n",
    "            inputs = batch[0]\n",
    "            loss = train_step(inputs, vae_optimizer)\n",
    "            epoch_loss += loss\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {epoch_loss / len(train_dataset):.4f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "tracks = tracks.astype('float32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(tracks.values)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(512)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: (tf.reshape(x, [-1, 25]), x))\n",
    "vae_optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.7045\n",
      "Epoch 2: Loss = 0.6668\n",
      "Epoch 3: Loss = 0.6313\n",
      "Epoch 4: Loss = 0.5971\n",
      "Epoch 5: Loss = 0.5644\n",
      "Epoch 6: Loss = 0.5328\n",
      "Epoch 7: Loss = 0.5010\n",
      "Epoch 8: Loss = 0.4734\n",
      "Epoch 9: Loss = 0.4533\n",
      "Epoch 10: Loss = 0.4404\n",
      "Epoch 11: Loss = 0.4328\n",
      "Epoch 12: Loss = 0.4288\n",
      "Epoch 13: Loss = 0.4266\n",
      "Epoch 14: Loss = 0.4257\n",
      "Epoch 15: Loss = 0.4252\n",
      "Epoch 16: Loss = 0.4248\n",
      "Epoch 17: Loss = 0.4247\n",
      "Epoch 18: Loss = 0.4246\n",
      "Epoch 19: Loss = 0.4245\n",
      "Epoch 20: Loss = 0.4244\n",
      "Epoch 21: Loss = 0.4244\n",
      "Epoch 22: Loss = 0.4243\n",
      "Epoch 23: Loss = 0.4243\n",
      "Epoch 24: Loss = 0.4242\n",
      "Epoch 25: Loss = 0.4241\n",
      "Epoch 26: Loss = 0.4241\n",
      "Epoch 27: Loss = 0.4240\n",
      "Epoch 28: Loss = 0.4239\n",
      "Epoch 29: Loss = 0.4239\n",
      "Epoch 30: Loss = 0.4237\n",
      "Epoch 31: Loss = 0.4237\n",
      "Epoch 32: Loss = 0.4234\n",
      "Epoch 33: Loss = 0.4232\n",
      "Epoch 34: Loss = 0.4230\n",
      "Epoch 35: Loss = 0.4229\n",
      "Epoch 36: Loss = 0.4226\n",
      "Epoch 37: Loss = 0.4223\n",
      "Epoch 38: Loss = 0.4215\n",
      "Epoch 39: Loss = 0.4203\n",
      "Epoch 40: Loss = 0.4200\n",
      "Epoch 41: Loss = 0.4201\n",
      "Epoch 42: Loss = 0.4206\n",
      "Epoch 43: Loss = 0.4205\n",
      "Epoch 44: Loss = 0.4210\n",
      "Epoch 45: Loss = 0.4207\n",
      "Epoch 46: Loss = 0.4206\n",
      "Epoch 47: Loss = 0.4205\n",
      "Epoch 48: Loss = 0.4207\n",
      "Epoch 49: Loss = 0.4204\n",
      "Epoch 50: Loss = 0.4203\n",
      "Epoch 51: Loss = 0.4205\n",
      "Epoch 52: Loss = 0.4204\n",
      "Epoch 53: Loss = 0.4203\n",
      "Epoch 54: Loss = 0.4204\n",
      "Epoch 55: Loss = 0.4203\n",
      "Epoch 56: Loss = 0.4202\n",
      "Epoch 57: Loss = 0.4202\n",
      "Epoch 58: Loss = 0.4201\n",
      "Epoch 59: Loss = 0.4199\n",
      "Epoch 60: Loss = 0.4201\n",
      "Epoch 61: Loss = 0.4200\n",
      "Epoch 62: Loss = 0.4200\n",
      "Epoch 63: Loss = 0.4201\n",
      "Epoch 64: Loss = 0.4200\n",
      "Epoch 65: Loss = 0.4199\n",
      "Epoch 66: Loss = 0.4200\n",
      "Epoch 67: Loss = 0.4199\n",
      "Epoch 68: Loss = 0.4199\n",
      "Epoch 69: Loss = 0.4198\n",
      "Epoch 70: Loss = 0.4200\n",
      "Epoch 71: Loss = 0.4198\n",
      "Epoch 72: Loss = 0.4199\n",
      "Epoch 73: Loss = 0.4196\n",
      "Epoch 74: Loss = 0.4198\n",
      "Epoch 75: Loss = 0.4197\n",
      "Epoch 76: Loss = 0.4199\n",
      "Epoch 77: Loss = 0.4197\n",
      "Epoch 78: Loss = 0.4197\n",
      "Epoch 79: Loss = 0.4197\n",
      "Epoch 80: Loss = 0.4197\n",
      "Epoch 81: Loss = 0.4195\n",
      "Epoch 82: Loss = 0.4196\n",
      "Epoch 83: Loss = 0.4197\n",
      "Epoch 84: Loss = 0.4197\n",
      "Epoch 85: Loss = 0.4198\n",
      "Epoch 86: Loss = 0.4198\n",
      "Epoch 87: Loss = 0.4196\n",
      "Epoch 88: Loss = 0.4196\n",
      "Epoch 89: Loss = 0.4195\n",
      "Epoch 90: Loss = 0.4196\n",
      "Epoch 91: Loss = 0.4197\n",
      "Epoch 92: Loss = 0.4198\n",
      "Epoch 93: Loss = 0.4195\n",
      "Epoch 94: Loss = 0.4194\n",
      "Epoch 95: Loss = 0.4196\n",
      "Epoch 96: Loss = 0.4196\n",
      "Epoch 97: Loss = 0.4194\n",
      "Epoch 98: Loss = 0.4196\n",
      "Epoch 99: Loss = 0.4197\n",
      "Epoch 100: Loss = 0.4195\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, epochs=100, vae_optimizer=vae_optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}